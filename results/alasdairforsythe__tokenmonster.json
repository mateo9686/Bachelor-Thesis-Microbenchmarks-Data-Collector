{
  "Name": "alasdairforsythe/tokenmonster",
  "Path": "./repositories/alasdairforsythe__tokenmonster",
  "GoVersion": "n/a",
  "BenchmarkData": {
    "timestamp": "2023-10-26T11:44:55Z",
    "benchmarkCount": 0,
    "benchmarkSuiteCount": 0,
    "successfulBenchmarkCount": 0,
    "successfulBenchmarkSuitesCount": 0,
    "goos": "n/a",
    "goarch": "n/a",
    "suites": []
  },
  "GitRepo": {
    "full_name": "alasdairforsythe/tokenmonster",
    "name": "tokenmonster",
    "private": false,
    "html_url": "https://github.com/alasdairforsythe/tokenmonster",
    "description": "Ungreedy subword tokenizer and vocabulary trainer for Python, Go \u0026 Javascript",
    "fork": false,
    "created_at": "2023-05-12T04:58:39Z",
    "updated_at": "2023-10-22T23:12:29Z",
    "pushed_at": "2023-09-05T09:49:40Z",
    "ssh_url": "git@github.com:alasdairforsythe/tokenmonster.git",
    "stargazers_count": 383,
    "watchers_count": 383,
    "has_issues": true,
    "has_projects": true,
    "has_downloads": true,
    "has_wiki": true,
    "has_pages": false,
    "has_discussions": true,
    "forks": 13,
    "language": "Go",
    "archived": false,
    "disabled": false,
    "open_issues": 6,
    "topics": [
      "text-tokenization",
      "tokenisation",
      "tokenization",
      "tokenize",
      "tokenizer",
      "tokenizing",
      "vocabulary",
      "vocabulary-builder",
      "vocabulary-generator"
    ],
    "allow_forking": true,
    "is_template": false,
    "cloning_error": "",
    "score": 1,
    "license": {
      "key": "mit",
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit",
      "spdx_id": "MIT",
      "node_id": "MDc6TGljZW5zZTEz",
      "html_url": ""
    }
  },
  "CodeStatistics": {
    "Count": 9,
    "Lines": 10111,
    "Blank": 533,
    "Code": 8857,
    "Comment": 721,
    "Bytes": 349808,
    "Complexity": 2384
  }
}